---
title: "导航与SLAM笔记"
date: 2024-01-01 10:00:00 +0800
categories: [Others]
layout: single
author_profile: true
---

# Navigation:From 

## SLAM
探索未知环境的同时，进行自我定位并构建环境地图
localization & mapping
定位：基于滤波的方法 / 基于图优化的方法

基于滤波的方法通过不断更新机器人的状态估计来实现定位，而基于图优化的方法则是通过最小化所有测量值与估计值之间的误差来优化机器人的轨迹

地图构建：特征地图/栅格地图  特征地图通过提取环境中的关键特征（如角点、边缘等）来构建地图，而栅格地图则是将环境划分为多个小栅格，并标记每个栅格的状态（如占用、空闲）。

SLAM算法的基本流程可以分为以下几个步骤：

感知环境：机器人通过搭载的传感器（如雷达、摄像头）感知周围环境。
提取特征：从感知到的数据中提取出有用的信息，如特征点、边缘等。
数据关联：将提取出的特征与已知的地图或之前的观测进行匹配，以确定自身的位置。
状态估计：利用滤波器或图优化方法对机器人的位置和地图进行估计和更新。
地图更新：根据最新的位置估计，更新地图信息。

二维激光SLAM、三维激光SLAM，以及视觉SLAM。

问题：计算资源 
语义slam

## 语义slam

VLMaps：最早的版本。根据 arXiv 显示，VLMaps 的预印本 “Visual Language Maps for Robot Navigation” 上传于 2022 年10月。
arXiv
+2
vlmaps.github.io
+2

GitHub 仓库 “vlmaps/vlmaps” 显示用于 ICRA2023。


AVLMaps：在 VLMaps 基础上加入音频模态。根据 arXiv， “Audio Visual Language Maps for Robot Navigation” 上传于 2023 年3月。


GitHub 仓库 “avlmaps/AVLMaps” 指明为 ISER2023 会议实现。


MSLMaps：最新的版本，将 VLMaps 和 AVLMaps 整合成 “Multimodal Spatial Language Maps” 的框架

# Multimodal Spatial Language Maps for Robot Navigation and Manipulation
> https://arxiv.org/pdf/2506.06862

统一了spatial language maps
多模态 -->  空间 --> 语义映射

## Motivation & 
multimodal spatial language maps as a spatial map representation that fuses pretrained multimodal features with a 3D reconstruction of the environment


创新点：

# NaVILA: Legged Robot Vision-Language-Action Model for Navigation
> https://arxiv.org/pdf/2412.04453
> https://navila-bot.github.io/

## Motivation && Background

## Data

## Result

We introduce an end-to-end vision-based locomotion policy trained without teacher-student distillation.




