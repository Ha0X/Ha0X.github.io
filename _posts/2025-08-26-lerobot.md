---
title: "LeRobot 笔记"
date: 2024-08-26 10:00:00 +0800
categories: [Others]
layout: single
author_profile: true
---

# lerobot 

### Soarm-101
7 自由度
- Base / Shoulder Pan	
- Shoulder Lift
- Elbow Flex	
- Wrist Flex
- Wrist Roll	
- Gripper

主臂(leader arm)和从臂（follwer arm）

### 电机中位校准
舵机的控制信号是 PWM 信号：周期 20ms，高电平 1–2ms。1.5ms（1500μs） 代表中位。

如果没有中位校准：控制信号是“中位”时（通常是 PWM 1500μs），舵机并不在物理中心，而是偏左或偏右。表现为上电后舵机“歪头”或自动撞机械限位。


在 usb

### 摄像头的使用
推荐使用两个摄像头 一个放在前方 俯视（top view） 一个放在侧面 侧视图（side view） 
由于桌子比较小 可能并 摄像头的画面质量不高 可能是效果不好的原因之一



### 操作步骤
```bash
lerobot-find-port
```


### movelt+Rviz路径规划
MoveIt + RViz 正常加载你的机械臂（so101），能在 RViz 里 plan/可视化。

接两路 USB 摄像头，在 ROS2 里发布图像话题

### 遥操作


### ACT（Action Chunking Transformer）

#### 模型结构：CVAE + Transformer
ACT 用了条件变分自动编码器（Conditional VAE, CVAE）来建模人类演示数据中的 不确定性/多样性：人演示中可能在同任务上有不同动作轨迹，模型不是只学“平均行为”而是学“动作分布”。 

Transformer 用于处理“视觉 + 状态 (如关节位置) + 未来动作块”之间的序列建模。具体来说：

Encoder：编码动作块 +状态 → 产生 latent z。

Decoder (Policy)：条件于当前观察（视觉图像、关节状态）+ z → 输出未来动作序列。

动作分块 (Action Chunking)
与传统每一时刻输出一个动作不同，ACT 在每个时刻 预测未来一段时间（k 个时刻）的一系列动作
虽然每次预测一段动作，但如果直接每 k 步才预测一次，机器人可能动作不连贯／响应慢。ACT 引入“每个时刻都预测一段”且 “用加权平均”融合多个预测重叠部分。

```bash
cd lerobot && python lerobot/scripts/train.py \
  --dataset.repo_id=${HF_USER}/il_gym0 \
  --policy.type=act \
  --output_dir=outputs/train/il_sim_test0 \
  --job_name=il_sim_test \
  --policy.device=cuda \
  --wandb.enable=true
```

### SmolVLA
action chunk
异步
--> 模型规模小 推理速度快
```bash
cd lerobot && python lerobot/scripts/train.py \
  --policy.path=lerobot/smolvla_base \
  --dataset.repo_id=${HF_USER}/mydataset \
  --batch_size=64 \
  --steps=20000 \
  --output_dir=outputs/train/my_smolvla \
  --job_name=my_smolvla_training \
  --policy.device=cuda \
  --wandb.enable=true
```