---
title: "Pi0.5 笔记"
date: 2025-08-25 11:00:00 +0800
categories: [VLA]
layout: single
author_profile: true
---

# pi0:https://arxiv.org/abs/2410.24164
>A human being should be able to change a diaper, plan an invasion, butcher a hog, conn a ship, design a building, write a sonnet, balance accounts, build a wall, set a bone, comfort the dying, take orders, give orders, cooperate, act alone, solve equations, analyze a new problem, pitch manure, program a computer, cook a tasty meal, fight efficiently, die gallantly. Specialization is for insects.
——Robert A. Heinlein, Time Enough for Love


因此，pi0的核心模型架构为：VLM + 动作专家（Conditional Flow Matching）
- VLM基座：PaliGemma 3B（语义理解多模态输入）

- 动作专家：Conditional Flow Matching（连续动作序列生成）

### 推理阶段
输入 多V相机 机器人state 文本prompt

### 实验评估
VLA任务的评估指标是每个任务和方法的 10 个 episodes（事件）的平均标准化分数，其中episode完全成功时得分为 1.0，部分成功得部分分数。

1.在预训练数据中存在的各种任务上
2.π0 的指令跟随能力如何？

https://arxiv.org/abs/2504.16054


# pi0-fast
一种叫FAST的tokenization方法，它依赖于离散余弦变换 (DCT)，这是一种在JPEG或MP3编解码器中常用的信号压缩技术。同时，将DCT与字节对编码 (Byte-Pair Encoding，BPE) 相结合，后者是一种常用于训练大型语言模型的压缩算法。两者结合，能够将原始动作token压缩为少量的密集action token ，通常每个token包含原来正常状态下30到60个token，比之前的动作tokenization方法压缩率提高了10倍。

作者受到Transfusion启发，该方法在一个单一Transformer上使用多个目标进行训练，其中：

- 对于连续输出的token，使用流匹配损失；

- 对于离散输出的token，则使用交叉熵损失。

mixtur eperts

连续的动作

独立“Action Expert” 权重（MoE结构）处理动作/状态

多平台、多形态机器人 ≈ 10 000 h 示范

高频（50 Hz）连续控制

语言/图像均为 Transformer 的 token 输入

# hi robot

# pi 0.5