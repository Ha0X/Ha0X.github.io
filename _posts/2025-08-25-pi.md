---
title: "Pi0.5 笔记"
date: 2025-08-25 11:00:00 +0800
categories: [VLA]
layout: single
author_profile: true
---

# Pi系列

## Pi0

> https://arxiv.org/abs/2410.24164

### 基本介绍
Pi0的核心模型架构为：VLM + 动作专家（Conditional Flow Matching）
- VLM基座：PaliGemma 3B（语义理解多模态输入）（互联网数据）

Transfusion（Token Fusion Transformer）将语言、图像、状态 token 混合输入同一 Transformer，实现跨模态对齐。
三个摄像头视角（左臂 右臂 头顶）三个vit


- 动作专家：Conditional Flow Matching（连续动作序列生成）

**输入：** 上下文嵌入（VLM 输出） + 当前状态向量
混合专家 快慢系统

**输出：**一整个动作区块（action chunk），连续 50 步控制命令

Conditional Flow matching( CFM )通过学习一个“速度场”  $v_\theta(x, t)$，从噪声轨迹逐渐流向真实动作轨迹（区别于ACT），能生成平滑连续的轨迹


### 实验评估
VLA任务的评估指标是每个任务和方法的 10 个 episodes（事件）的平均标准化分数，其中episode完全成功时得分为 1.0，部分成功得部分分数。

评估了
1. 在预训练数据中存在的各种任务上
2. π0 的指令跟随能力如何？


## Pi0-Fast

> https://www.physicalintelligence.company/research/fast

### 基本介绍
目的：Fast

使用了一种Tokenization方法，它依赖于离散余弦变换 (DCT)，这是一种在JPEG或MP3编解码器中常用的信号压缩技术。

同时，将DCT与字节对编码 (Byte-Pair Encoding，BPE) 相结合，BPE是一种常用于训练大型语言模型的压缩算法。

Token的组合而非Token本身-->更高的信息密度-->Fast

事实上：会经历Fast编码再解码的过程（解码保证了不损失信息）


### 动作专家
MoE 架构（混合专家）：

- 每个专家专注不同动作模式（如抓取、推动、旋转等）；  
- 门控网络根据任务上下文（视觉 + 语言）动态选择或加权不同专家；  
- MoE 提升跨机器人平台的泛化性（可在 Franka、UR5、Allegro Hand 等间共享）。

这种结构让模型能根据任务语义自动分配“哪个动作子网络”起作用。


## Pi0.5(未开源)
### 基本介绍
解决泛化性的问题

cot-vla：利用视频生成 预测？ 想象 dreamer？ 引入语言？

异构数据

generated 子任务