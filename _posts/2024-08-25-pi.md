---
title: "Pi 系列笔记"
date: 2024-08-25 11:00:00 +0800
categories: [VLA]
layout: single
author_profile: true
---

# Pi 系列

## Pi0

> 论文链接：https://arxiv.org/abs/2410.24164

### 基本介绍

Pi0 的核心模型架构为：**VLM + 动作专家（Conditional Flow Matching）**

**VLM 基座：**
- PaliGemma 3B（语义理解多模态输入，基于互联网数据）
- Transfusion（Token Fusion Transformer）将语言、图像、状态 token 混合输入同一 Transformer，实现跨模态对齐
- 三个摄像头视角（左臂、右臂、头顶），使用三个 ViT 编码器

**动作专家：**
- Conditional Flow Matching（连续动作序列生成）
- **输入：** 上下文嵌入（VLM 输出）+ 当前状态向量
- 采用混合专家（MoE）架构，包含快慢系统
- **输出：** 一整个动作区块（action chunk），连续 50 步控制命令

Conditional Flow Matching (CFM) 通过学习一个"速度场" $v_\theta(x, t)$，从噪声轨迹逐渐流向真实动作轨迹（区别于 ACT），能生成平滑连续的轨迹。

### 实验评估

VLA 任务的评估指标是每个任务和方法的 10 个 episodes 的平均标准化分数，其中 episode 完全成功时得分为 1.0，部分成功得部分分数。

评估内容包括：
1. 在预训练数据中存在的各种任务上的表现
2. π0 的指令跟随能力

## Pi0-Fast

> 项目链接：https://www.physicalintelligence.company/research/fast

### 基本介绍

**目标：** 提升推理速度

使用了一种 Tokenization 方法，它依赖于离散余弦变换 (DCT)，这是一种在 JPEG 或 MP3 编解码器中常用的信号压缩技术。

同时，将 DCT 与字节对编码 (Byte-Pair Encoding, BPE) 相结合，BPE 是一种常用于训练大型语言模型的压缩算法。

通过 Token 的组合而非 Token 本身，实现更高的信息密度，从而提升速度。

实际上，会经历 Fast 编码再解码的过程（解码保证了不损失信息）。

### 动作专家

**MoE 架构（混合专家）：**

- 每个专家专注不同动作模式（如抓取、推动、旋转等）
- 门控网络根据任务上下文（视觉 + 语言）动态选择或加权不同专家
- MoE 提升跨机器人平台的泛化性（可在 Franka、UR5、Allegro Hand 等间共享）

这种结构让模型能根据任务语义自动分配"哪个动作子网络"起作用。

## Pi0.5（未开源）

### 基本介绍

**目标：** 解决泛化性问题

**主要改进方向：**
- CoT-VLA：利用视频生成进行预测，引入语言推理（类似 Dreamer）
- 异构数据融合
- 生成式子任务分解