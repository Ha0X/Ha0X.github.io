---
title: "OmniH2O 笔记"
date: 2025-08-26 10:00:00 +0800
categories: [运动控制]
layout: single
author_profile: true
---

# OmniH2O: Universal and Dexterous Human-to-Humanoid Whole-Body Teleoperation and Learning
 > https://omni.human2humanoid.com/


## A learning-based system for whole-body humanoid teleoperation and autonomy
不同类型的人类输入（人体姿态、VR等）实现Whole-body teleoperation（全身遥操作）& Learning-based autonomy（基于学习的自主运动）

## 创新点：
- teacher-student 
- isaac gym并行gpu训练
- 统一的关节接口 统一多种输入来源
- Human Motion Retargeting → RL-based Imitation (Phase 1) → Supervised distillation (Phase 2)

## 准备工作数据集：
AMASS：（ACCAD,BMLhandball,BMLmovi,CMU）
SMPL：参数化人体模型，输出 joint rotation, translation
Retargeting：将 SMPL 动作转为 humanoid 机器人对应关节轨迹
Feasibility Filter：去除无法执行或物理不稳定的样本（碰撞、姿态超限等）


## 代码理解：
legged_robot.py：
实现了基于 Isaac Gym 的腿足机器人仿真环境

"比较"机器人和人类动作
```python
# 机器人现在的状态

root_pos, root_rot     # 机器人身体中心的位置和朝向
body_pos, body_rot     # 机器人各个身体部位的位置和朝向  
dof_pos, dof_vel       # 机器人关节的角度和速度

# 人类参考动作（目标）

ref_body_pos, ref_body_rot    # 人类各个身体部位应该在的位置和朝向
ref_root_vel, ref_root_ang_vel # 人类身体中心应该有的速度
ref_dof_pos, ref_dof_vel      # 人类关节应该有的角度和速度
```

step
load_expert
check_termination

差异：关节速度，身体朝向，位置，移动速度，


### h1_teleop_config.py

定义环境配置+ppo算法
初始+域随机化+noise
env（并行环境数，特权观测维度，动作维度）
control：PD控制器
rewards：。。。
motion：
、

### train_hydra.py:



### ppo.py :
ppo+模仿学习
存储 RL 状态 (obs, action, reward)+存储额外 kinematic dict（包含教师动作、关键点等）
PPO + Kinematic Loss + KL Loss + Smoothness Loss + DAgger loss
支持多阶段更新（kin_only / dagger_anneal）  可先模仿后强化
Action Smoothness（动作连续性约束）

问题：人类与机器人的「动作空间」不同
vae/teacher-student
lagrangian：约束——更安全（硬约束）


六个任务
teacher-student
isaac-gym 并行gpu 

humanoid_im.py：环境实现


### 复现
1. 训练teacher policy

2. 训练student policy

### slurm训练脚本
```bash
source ~/.bashrc
conda activate isaacgym

export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH
```