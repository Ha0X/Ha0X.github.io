---
title: "Code as Policies (CAP) 笔记"
date: 2025-08-26 10:00:00 +0800
categories: [新建]
layout: single
author_profile: true
---

# code as policies

> https://code-as-policies.github.io/

## # Code as Policies: Language Model Programs for Embodied Control  

**作者**：Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman, Brian Ichter, Pete Florence, Andy Zeng  
**链接**：[https://code-as-policies.github.io/](https://code-as-policies.github.io/)

---

## 摘要  
- 最近的大型语言模型（LLM）在代码补全任务上表现出色，能够根据 docstring 生成简单的 Python 程序。  
- 本文提出将这些“能写代码”的语言模型用于机器人控制策略（policy）生成：即给定自然语言命令，生成机器人控制的程序代码。  
- 这些策略（policy code）可以处理感知输出（例如物体检测器的结果）并调用控制 API（如机械臂动作、移动控制）。  
- 通过 few‑shot 提示（给出一些语言命令 + 对应策略代码），语言模型能够接收新的命令，并自主组合 API 调用以生成新的策略代码。  
- 使用经典逻辑结构 + 第三方库（如 NumPy、Shapely）进行空间-几何推理，模型生成的代码具备如下能力：  
  1. 空间‑几何推理能力  
  2. 对新指令的泛化能力  
  3. 能根据模糊描述（如“faster”）结合上下文产生精确数值（如速度）  
- 本文将此类模型生成的程序称为“语言模型程序”（LMPs），即“代码即策略”（Code as Policies）在机器人控制中的形式化。  
- 方法之一为“分层代码生成提示”（hierarchical code‐gen prompting）：递归地定义未定义函数，从而生成功能更复杂的代码。该方法使得模型在 HumanEval 基准上的成绩达到 **39.8%** 的解题率。

---

## 实验设置与任务类型  

### 桌面操作：积木 (Blocks)
- **任务描述**：
  - 机器人根据自然语言指令操作积木，目标是通过控制和空间推理来完成物体移动或排列。
- **指令示例**：
  - “把所有积木放在靠近上方的一条水平线上”  
  - “把天空颜色块移动到红块和第二个块之间”  
  - “你为什么移动了绿色块？”  
  - “哪个块你移动了？”  
  - “将积木围绕中心摆成一个正方形”  
  - “把正方形调大” → “撤销刚才” → “将正方形旋转45度”  
  - …
- **提示模块结构**：
  - High‑Level UI | Parse Object Names | Parse Positions | Parse Questions | Function Generation  

### 桌面操作：积木 + 碗 (Blocks and Bowls)  
- **任务描述**：
  - 在有碗的场景中，根据指令将积木放入碗内，执行位置调整等任务。
- **指令示例**：
  - “把红块放在最右碗的左边”  
  - “现在把它移动到最远离它的那一侧”  
  - “红块左边有几个碗？”  
  - “把颜色不匹配的积木放进碗里”  
  - “将积木摆成一个垂直线，长20 cm，位于蓝碗之下10 cm”  
  - …
- **提示模块结构**：
  - High‑Level UI | Parse Object Names | Parse Positions | Parse Questions | Function Generation  

### 桌面操作：水果、水瓶与盘子 (Fruits, Bottles, Plates)  
- **任务描述**：
  - 对水果、瓶子和盘子执行位置和数量判断，移动物体等任务。
- **指令示例**：
  - “有多少水果？”  
  - “告诉我它们的名字”  
  - “绿色盘子上有水果吗？”  
  - “把所有水果放到绿色盘子，把瓶子放到蓝色盘子”  
  - “把最小的水果移回黄色盘子”  
  - “等到你看到一个鸡蛋，把它放到绿色盘子”  
  - “把最暗的物体放到有苹果的盘子里”  
  - …
- **提示模块结构**：
  - High‑Level UI | Parse Object Names | Parse Positions | Parse Questions | Function Generation  

### 白板绘图 (Whiteboard Drawing)  
- **任务描述**：
  - 在虚拟白板上，生成不同的几何图形和线条。
- **指令示例**：
  - “在中间画一个 5 cm 的六边形”  
  - “画一条线将六边形平分”  
  - “把它们都放大”  
  - “擦掉六边形和那条线”  
  - “在右上角画太阳作为圆”  
  - “在下方画地面作为线”  
  - “在地面上画一个金字塔（三角形）”  
  - “在左边稍做一个更小的金字塔”  
  - “擦掉太阳、地面和金字塔”  
  - “在积木周围画圈”  
  - “在更甜的水果周围画个正方形”  
  - …
- **提示模块结构**：
  - High‑Level UI | Parse Object Names | Parse Shape Points | Transform Shape Points | Function Generation  

### 移动机器人：导航 (Mobile Robot: Navigation)  
- **任务描述**：
  - 控制移动机器人执行导航任务，如围绕物体、路径调整等。
- **指令示例**：
  - “在办公室椅子周围沿 3 m×2 m 矩形移动”  
  - “同样做但旋转 45° 顺时针”  
  - “在凳子周围做一个 1.5 m 的正方形，检查每一步是否看到可口可乐罐，只有看到才停止移动”  
  - “跟随椅子构成的二维凸包，并 2× 缩放”  
  - “在桌子和台面之间来回两次”  
  - …
- **提示模块结构**：
  - High‑Level UI | Parse Object Names | Parse Positions | Transform Points | Function Generation  

### 移动机器人：操作 (Mobile Robot: Manipulation)  
- **任务描述**：
  - 控制移动机器人操作物体，执行如放置、拿取等任务。
- **指令示例**：
  - “把可口可乐罐和苹果放到它们各自的箱子里”  
  - “从桌子上拿可口可乐罐，把它放到水果桌子上水果的中间”  
  - “桌子上有多少水果？”  
  - …
- **提示模块结构**：
  - High‑Level UI | Parse Object Names | Parse Positions | Transform Points | Function Generation  

---

## 实验细节  

### 1. **实验平台与设置**  
- **硬件平台**：  
  - 我们的实验在多个平台上进行，包括：  
    - **移动机器人平台**：使用真实的移动机器人进行操作和导航任务。  
    - **机械臂平台**：用于执行更细致的操作任务，如物体抓取和放置。  
    - **仿真环境**：包括使用 Gazebo 仿真环境来测试代码生成的有效性。  
- **环境设置**：  
  - 所有实验均在特定的操作环境中进行，这些环境通过标定和传感器进行配置，保证任务执行的准确性和高效性。  
  - 例如，桌面操作任务通常在标准桌面环境中进行，并提供一些标识物（如色块）来确保任务能够正确执行。

### 2. **HumanEval 结果**  
- **测试目标**：  
  - 该实验评估模型在 **HumanEval** 基准上的代码生成能力。  
  - **HumanEval** 是用于评估程序生成能力的标准数据集，包含 164 道编程题。  
- **模型表现**：  
  - 使用分层代码生成提示（hierarchical code-gen prompting），模型在 HumanEval 基准上的解题率达到了 **39.8%**，相比于普通的 GPT 模型，具有显著的提高。

### 3. **任务成功率与性能**  
- **桌面任务成功率**：  
  - 对于积木和碗的操作任务，模型在仿真中的成功率超过了 **90%**，而在真实机器人平台中，由于传感器和执行环境的差异，成功率为 **80%**。  
- **导航任务性能**：  
  - 在移动机器人导航任务中，模型能够准确执行指令并完成路径规划，特别是在复杂的任务，如旋转和避障，性能稳定。  
  - 在不确定的动态环境中（如多人环境或物品干扰），模型的成功率略有下降，表明其在实时适应性方面仍有改进空间。

---

## 方法亮点  

- **提示结构（Prompting）**：将示例语言命令 + 对应策略代码提供给语言模型，通过 few‑shot 方式让模型学习“语言 → 策略代码”的映射。  
- **分层代码生成（Hierarchical Code‑Gen）**：当生成策略代码时，若遇到未定义函数，可递归询问模型来定义这些函数，从而生成功能更复杂的程序。  
- **空间‑几何推理与行为常识**：策略代码中不仅调用控制 API，还可能借助 NumPy、Shapely 等库来处理位置、几何变换、轨迹参数等，从而具备几何推理能力。  
- **泛化能力**：模型在见到新的语言指令（未在示例中出现）时，仍能组合已有函数/库调用生成新的策略代码。  
- **实机器人平台验证**：该方法不仅在仿真中实现，也在多个真实机器人平台上演示。  

---

## 拓展链接 &资源  

- 论文预印本：arXiv “Code as Policies: Language Model Programs for Embodied Control” ([link](https://code-as-policies.github.io/))  
- 代码仓库：网页提供链接（GitHub） ([link](https://code-as-policies.github.io/))  
- Colab 演示：网页提供链接 ([link](https://code-as-policies.github.io/))  
- Blog 文章：网页提供链接 ([link](https://code-as-policies.github.io/))  
- Demo 视频：网页提供多个实验视频及声音说明 ([link](https://code-as-policies.github.io/))  

---

## 我的思考 / 待解决问题  
- 虽然模型能根据语言命令生成控制代码，但在真实机器人上，多数任务可能仍需要人工干预（例如感知预处理、错误检测、物理安全等）。未来如何减少这些人工环节？  
- 在更复杂、动态、不确定的环境（如人群、未知物体、复杂场景）中，这种方法的泛化能力和安全性如何？  
- 提示工程（prompt engineering）在这里起到关键作用：如何设计示例命令、如何结构化提示，使得模型生成有效控制策略？是否有自动化方法？  
- 生成代码的可验证性：机器人控制程序一旦出错可能造成损坏或伤害，如何引入验证、仿真、形式化检查等机制？  
- 从产业或实际部署角度：这种方法如何与传统机器人系统（感知流水线、控制闭环、安全模块）整合？成本及收益如何？